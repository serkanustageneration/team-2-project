
# What is this Project about? CI/CD
We are making an ETL pipeline for a café that has hundreds of outlets across the country.

Due to the demand the company is receiving, they need to figure out how they can best target new and returning customers, and also understand which products are selling well.

They are experiencing issues with collating and analysing the data they are producing at each branch, as their technical setup is limited.

We have been asked to step in and provide consultation on what they need to do in order to grow their technical offerings, so that they can continue to accelerate their growth.

# Current Situation
A CSV file containing data about every transaction they made for that day is generated at 8pm and the data is uploaded to a piece of software installed in the back office computers.

Also Daily, weekly or monthly reports for sales figures and other related business metrics are created.

# However they are facing the following problems:
- The software currently being used only generates reports for single branches.
- It is time consuming to collate data on all branches, and gathering meaningful data for the company on the whole is difficult, due to the limitations of the software.

## As a result
- The company currently has **no way of identifying trends**, meaning they are potentially losing out on major revenue streams.
- They are in desperate need of help putting together a platform that will allow them to easily understand all of the data they are producing.

# Solution
We are tasks to create solutions to solve the problem they're facing.

We have been tasked with building a fully scalable ETL (**E**xtract, **T**ransform, **L**oad) pipeline to handle large volumes of transaction data for the business. This pipeline will collect all the transaction data generated by each individual café and place it in a single location. By being able to easily query the company's data as a whole, the client will drastically increase their ability to identify company-wide trends and insights.

We will be in charge of figuring out how to obtain, process, store and analyse this data.

# Our Goal
- Each night a CSV for each branch will be uploaded to the cloud
- The system we have developed will read each file and perform ETL steps
- Data will be stored in a data warehouse
- Data analytics software will be used to create Business Intelligence analytics for the client
- Application monitoring software will be used to produce operational metrics, such as system errors, up-time and more


# Our Team Leader
Ahmed M.

# Scrum Master	
Week 1	Marshall C.
Week 2	Bharat P.
Week 3	Ahmed M.
Week 4	Serkan U.
Week 5	Gita B.

